import requests
from bs4 import BeautifulSoup as BS
import pandas as pd
from time import sleep

page = requests.get("https://nplus1.ru")
soup = BS(page.text)

links = []
for link in soup.find_all("a"):
   if '/news' in link.get("href"):
    links.append(link.get("href"))
    
full_links = ["https://nplus1.ru/" + u for u in links]

def get_news(url): 
    page0 = requests.get(url)
    soup0 = BS(page0.text)
    title = soup0.find_all("title")[0].text
    date = soup0.find_all("meta",  {"itemprop": "datePublished"})[0].get("content")
    author = soup0.find_all("meta",
                                   {"name": "author"})[0].get("content")
    desc = soup0.find_all("meta", 
                                   {"property": "og:description"})[0].get("content")
    diffc = float(soup0.find_all("span",
                                   {"class": "difficult-value"})[0].text)
    desc = desc.replace("/ax0", " ")
    time = soup0.find_all("time")[0].find_all("span")[0].text
    texts_raw = soup0.find_all("p", {"class": None})
    texts = [t.text for t in texts_raw]
    final_text = " ".join(texts)
    final_texts = final_text.replace("\xa0", " ").replace("\n", " ")
    final_texts.split("Нашли опечатку?")[0]
    return title, date, time, author, diffc, final_texts

info = []
for f in full_links:
    L = get_news(f)
    info.append(L)
    sleep(1.5)
    
news = pd.DataFrame(info)
news.columns = ['title', 'data', 'time', 'author', 'difficulty', 'text']
news
